{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "719c1ecc-7188-4b00-9113-e84fc5bf8d93",
   "metadata": {},
   "source": [
    "# 22k4102 - IR ASSIGNMENT 1 - Boolean Model for Information Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1cabe0-7918-4a98-9e9b-ae62bc3216ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e0d7bc-6509-4d39-9651-1d4f65342fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    with open('Stopword-List.txt', 'r') as stopwordsFile:\n",
    "        stopwords = stopwordsFile.read().split()\n",
    "    ps = PorterStemmer()\n",
    "    text = text.lower().replace(\"-\", \" \") # to convert words like time-series into time series\n",
    "    terms = word_tokenize(text)\n",
    "    return [ps.stem(term) for term in terms if term.isalnum() and term not in stopwords and term != \"or\" and term != \"not\"] # The provided stopwords list does not contain or & not so I have handled them here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd15d89-8276-440b-a535-cba298bb4fcc",
   "metadata": {},
   "source": [
    "# Checking if preprocessing function is working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9c262e-b37e-4a10-a92f-b606a5a9bc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time', 'seri', 'classif']\n"
     ]
    }
   ],
   "source": [
    "x = preprocessing(\"time AND series OR classification\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d30cf56-80ab-4f4b-a593-290c9da17deb",
   "metadata": {},
   "source": [
    "# Building Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5826b0f2-1d1c-4368-bb63-110eabce55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildInvertedIndex(terms, docID, invertedIndex):\n",
    "    for term in terms:\n",
    "        if term not in invertedIndex:\n",
    "            invertedIndex[term] = []\n",
    "        if docID not in invertedIndex[term]:\n",
    "            invertedIndex[term].append(docID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a401e5-8ad8-4fb5-b880-dc9a100d00e5",
   "metadata": {},
   "source": [
    "# Building Positional Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f27bc87c-c587-456c-9d2c-a242f28fe0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPositionalIndex(terms, docID, positionalIndex):\n",
    "    for p, term in enumerate(terms):\n",
    "        if term not in positionalIndex:\n",
    "            positionalIndex[term] = {}\n",
    "        if docID not in positionalIndex[term]:\n",
    "            positionalIndex[term][docID] = []\n",
    "        positionalIndex[term][docID].append(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2c7cdc-acd0-4f4a-9975-8dd1d9864c52",
   "metadata": {},
   "source": [
    "# Saving Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8905149-4b44-48e8-b83d-5114c3dab6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveIndexes(invertedIndex, positionalIndex):\n",
    "    with open(\"invertedIndex.txt\", \"w\") as f1: # this will create a txt file for inverted index\n",
    "        json.dump(invertedIndex, f1)\n",
    "    with open(\"positionalIndex.txt\", \"w\") as f2: # # this will create a txt file for positional index\n",
    "        json.dump(positionalIndex, f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cf1eb-dba8-48b6-b646-d12cd39973d8",
   "metadata": {},
   "source": [
    "# Loading Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "379a6b51-b559-4050-a74c-02426692a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadIndexes():\n",
    "    with open(\"invertedIndex.txt\", \"r\") as f1: # loading the previously created inverted index txt file\n",
    "        invertedIndex = json.load(f1)\n",
    "    with open(\"positionalIndex.txt\", \"r\") as f2: # loading the previously created positional index txt file\n",
    "        positionalIndex = json.load(f2)\n",
    "    return invertedIndex, positionalIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ddab61-5518-4c09-be20-0672a6ca5e31",
   "metadata": {},
   "source": [
    "# Constructing Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274743a4-1338-42cb-81e3-255416f583ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invAndPosIndexes(directory):\n",
    "    invertedIndex = {} \n",
    "    positionalIndex = {}\n",
    "    \n",
    "    for docID in range(1, 449):\n",
    "        path = os.path.join(directory, f\"{docID}.txt\")\n",
    "        with open(path, 'r', encoding='latin-1') as document: # I have used latin-1 encoding because the encoding format of a couple of files is not utf-8. Latin-1 resolved that issue\n",
    "            terms = preprocessing(document.read())\n",
    "            buildInvertedIndex(terms, docID, invertedIndex) # this will build the inverted index\n",
    "            buildPositionalIndex(terms, docID, positionalIndex) # this will build the positional index\n",
    "    saveIndexes(invertedIndex, positionalIndex) # this will create file for both indexes\n",
    "    return invertedIndex, positionalIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8baf28-81a0-45d1-aa47-19c597e567f8",
   "metadata": {},
   "source": [
    "# Boolean Queries (Simple & Complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762cee81-da74-4b95-ae44-a979b3616408",
   "metadata": {},
   "outputs": [],
   "source": [
    "def booleanQuery(query, invertedIndex):\n",
    "    terms = preprocessing(query)\n",
    "    nonPreprocessedTerms = query.upper().split() # I have done this because preprocessing would remove stopwords like 'AND' which would not return correct boolean query result\n",
    "    operators = [] # a list of operators found in the query\n",
    "    \n",
    "    for i in range(len(nonPreprocessedTerms)):\n",
    "        if nonPreprocessedTerms[i].upper() == 'AND' or nonPreprocessedTerms[i].upper() == 'OR' or nonPreprocessedTerms[i].upper() == 'NOT':\n",
    "            operators.append(nonPreprocessedTerms[i])\n",
    "    \n",
    "    docs = set(range(1, 449))\n",
    "\n",
    "    if terms[0].upper() == \"NOT\": #Handling queries which have NOT as the first term for eg \"NOT autoencoders\"\n",
    "        return sorted(docs - set(invertedIndex.get(terms[1], set())))\n",
    "    \n",
    "    result = set(invertedIndex.get(terms[0], set()))\n",
    "\n",
    "    for i in range(len(operators)):\n",
    "        operator = operators[i]\n",
    "        nextTerm = set(invertedIndex.get(terms[i + 1], set()))\n",
    "        \n",
    "        if operator == \"AND\": # handling intersection i.e. AND\n",
    "            result &= nextTerm\n",
    "        elif operator == \"OR\": # handling union i.e. OR\n",
    "            result |= nextTerm \n",
    "        elif operator == \"NOT\": # handling difference i.e. NOT\n",
    "            result -= nextTerm\n",
    "    \n",
    "    return sorted(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e714b13c-7411-4cb6-aa71-8eeabb059c1a",
   "metadata": {},
   "source": [
    "# Proximity Queries\n",
    "## (I have assumed here that user will enter the proximity distance IN the query - I have extracted the distance directly from the query and passed it as a parameter in the proximityQuery function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e4137cf-1763-4d9e-9479-ca6abf510230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximityQuery(query, dist, positionalIndex):\n",
    "    terms = preprocessing(query)\n",
    "    print(terms)\n",
    "    term1 = terms[0]\n",
    "    term2 = terms[1]\n",
    "    \n",
    "    result = set()\n",
    "\n",
    "    if term1 in positionalIndex and term2 in positionalIndex: # if both terms exist in the positional index\n",
    "        docs = []                                             # this will store matching docs i.e the docs that contain both term1 and term2\n",
    "        for docID in positionalIndex[term1]:\n",
    "            if docID in positionalIndex[term2]:\n",
    "                docs.append(docID)\n",
    "\n",
    "        for docID in docs:\n",
    "            p1 = positionalIndex[term1][docID] # list of positions where term1 appears\n",
    "            p2 = positionalIndex[term2][docID] # list of positions where term2 appears\n",
    "\n",
    "            for individualP1 in p1: # individualP1 and individualP2 are position pointers\n",
    "                for individualP2 in p2:\n",
    "                    if abs(individualP1 - individualP2) <= dist+1: # I have done +1 in the distance because my positions are starting from 0 in the positional index.\n",
    "                        result.add(docID)\n",
    "                        break\n",
    "\n",
    "    return sorted(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17401a6-a72b-45dd-86b7-5b8933ee1b0b",
   "metadata": {},
   "source": [
    "# Importing Documents and building Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48d51338-64a3-43c5-98f8-d88138cd9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Abstracts\"\n",
    "invertedIndex, positionalIndex = invAndPosIndexes(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcb250e-abfa-4f05-8aab-c1fb99a45390",
   "metadata": {},
   "source": [
    "# Loading Indexes from File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a13d08fb-ea7d-46d1-861c-6b3cedf20f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedIndex, positionalIndex = loadIndexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff60e58-8133-4d37-941d-6c5bd0569c12",
   "metadata": {},
   "source": [
    "# Boolean Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56bf3c0-3a65-4c0d-9ddb-c3a36003db88",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"NOT autoencoder\"\n",
    "result = booleanQuery(query, invertedIndex)\n",
    "print(f\"Boolean Query Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73272b9-1f4d-41db-9a57-00145d5e80fe",
   "metadata": {},
   "source": [
    "# Proximity Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e829187a-8b9f-4de9-b2c8-bd0744f97021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "['featur', 'track']\n",
      "Proximity Query Result: ['13', '212']\n"
     ]
    }
   ],
   "source": [
    "query = \"feature track /5\"\n",
    "x = query.split()\n",
    "dist = int(x[2][1:])\n",
    "print(dist)\n",
    "result = proximityQuery(query, dist, positionalIndex)\n",
    "print(f\"Proximity Query Result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6e3250-307d-4b49-bd03-c5274bf9d5a0",
   "metadata": {},
   "source": [
    "# GUI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd617c9b-93da-4e26-b242-59001a554517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "def handleBooleanQuery():\n",
    "    booleanWindow = tk.Toplevel(root)\n",
    "    booleanWindow.title(\"Boolean Query\")\n",
    "    booleanWindow.geometry(\"600x200\")\n",
    "    booleanWindow.configure(bg=\"aqua\")\n",
    "\n",
    "    tk.Label(booleanWindow, text=\"Enter Boolean Query (for eg: 'time AND series AND classification'):\", font=(\"Arial\", 14), bg=\"aqua\", fg=\"black\").pack(pady=10)\n",
    "    booleanQueryEntry = tk.Entry(booleanWindow, width=50, font=(\"Arial\", 12))\n",
    "    booleanQueryEntry.pack(pady=10)\n",
    "\n",
    "    def processBooleanQuery():\n",
    "        query = booleanQueryEntry.get().strip()\n",
    "        if len(query.split()) > 5:\n",
    "            messagebox.showerror(\"Error\", \"Boolean Query length must not exceed 5 terms!\")\n",
    "            return\n",
    "        result = booleanQuery(query, invertedIndex)\n",
    "        messagebox.showinfo(\"Boolean Query Result\", f\"Result: {result}\")\n",
    "        booleanWindow.destroy()\n",
    "\n",
    "    tk.Button(booleanWindow, text=\"Submit\", command=processBooleanQuery, font=(\"Arial\", 12), bg=\"white\", fg=\"black\").pack(pady=10)\n",
    "\n",
    "def handleProximityQuery():\n",
    "    proximityWindow = tk.Toplevel(root)\n",
    "    proximityWindow.title(\"Proximity Query\")\n",
    "    proximityWindow.geometry(\"500x200\")\n",
    "    proximityWindow.configure(bg=\"aqua\")\n",
    "\n",
    "    tk.Label(proximityWindow, text=\"Enter Proximity Query (for eg: 'feature track /5'):\", font=(\"Arial\", 14), bg=\"aqua\", fg=\"black\").pack(pady=10)\n",
    "    proximityQueryEntry = tk.Entry(proximityWindow, width=50, font=(\"Arial\", 12))\n",
    "    proximityQueryEntry.pack(pady=10)\n",
    "\n",
    "    def processProximityQuery():\n",
    "        query = proximityQueryEntry.get().strip()\n",
    "        x = query.split()\n",
    "        if len(x) != 3:\n",
    "            messagebox.showerror(\"Error\", \"Proximity Query must be of exactly length = 3!\")\n",
    "            return\n",
    "        try:\n",
    "            dist = int(x[2][1:])\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Invalid distance!\")\n",
    "            return\n",
    "        result = proximityQuery(query, dist, positionalIndex)\n",
    "        messagebox.showinfo(\"Proximity Query Result\", f\"Result: {result}\")\n",
    "        proximityWindow.destroy()\n",
    "\n",
    "    tk.Button(proximityWindow, text=\"Submit\", command=processProximityQuery, font=(\"Arial\", 12), bg=\"white\", fg=\"black\").pack(pady=10)\n",
    "\n",
    "def handleExit():\n",
    "    exitWindow = tk.Toplevel(root)\n",
    "    exitWindow.geometry(\"400x150\")\n",
    "    exitWindow.configure(bg=\"aqua\")\n",
    "\n",
    "    tk.Label(exitWindow, text=\"Thank you!\", font=(\"Arial\", 16), bg=\"aqua\", fg=\"black\").pack(pady=20)\n",
    "    tk.Button(exitWindow, text=\"Close\", command=root.destroy, font=(\"Arial\", 12), bg=\"red\", fg=\"black\").pack(pady=10)\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Boolean Model for IR\")\n",
    "root.geometry(\"600x400\")\n",
    "root.configure(bg=\"aqua\")\n",
    "\n",
    "tk.Label(root, text=\"Select your choice:\", font=(\"Arial\", 18), bg=\"aqua\", fg=\"black\").pack(pady=20)\n",
    "tk.Button(root, text=\"1. Boolean Query\", command=handleBooleanQuery, font=(\"Arial\", 14), width=20, bg=\"white\", fg=\"black\").pack(pady=10)\n",
    "tk.Button(root, text=\"2. Proximity Query\", command=handleProximityQuery, font=(\"Arial\", 14), width=20, bg=\"white\", fg=\"black\").pack(pady=10)\n",
    "tk.Button(root, text=\"3. Exit\", command=handleExit, font=(\"Arial\", 14), width=20, bg=\"red\", fg=\"black\").pack(pady=10)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d121327-f0a6-4b89-b929-728a6547bcbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
